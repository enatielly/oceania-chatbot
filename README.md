# Ocean AI - Chatbot sobre o Oceano AtlÃ¢ntico

Sistema de chat inteligente com RAG (Retrieval-Augmented Generation) para consulta de dados sobre o Oceano AtlÃ¢ntico adjacente Ã  costa brasileira.

## ğŸŒŠ Sobre o Projeto

Ocean AI Ã© um chatbot especializado que responde perguntas sobre as Ã¡guas marinhas brasileiras no Oceano AtlÃ¢ntico usando **apenas dados oficiais** de 8 fontes cientÃ­ficas.

### Fontes de Dados

1. **OBIS** - Ocean Biodiversity Information System
2. **GBIF** - Global Biodiversity Information Facility
3. **Copernicus Marine** - Dados oceanogrÃ¡ficos europeus
4. **ICMBio SALVE** - EspÃ©cies ameaÃ§adas
5. **Dados.gov.br** - Unidades de conservaÃ§Ã£o
6. **World Bank** - Indicadores climÃ¡ticos
7. **IPCC** - RelatÃ³rios sobre mudanÃ§as climÃ¡ticas
8. **UNESCO** - DÃ©cada dos Oceanos

### Tecnologias

- **Frontend**: Streamlit
- **RAG Engine**: SentenceTransformers + FAISS
- **LLM**: Llama 3.1 70B via Groq API
- **Embeddings**: paraphrase-multilingual-mpnet-base-v2

## ğŸš€ Como Executar Localmente

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/oceania-chatbot.git
cd oceania-chatbot
```

### 2. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 3. Configure a API Key do Groq

Crie um arquivo `.env` na raiz do projeto:

```env
GROQ_API_KEY=sua_chave_aqui
```

**Como obter a chave Groq**:
1. Acesse https://console.groq.com/
2. Crie uma conta gratuita
3. Gere uma API key
4. Cole no arquivo `.env`

### 4. Colete os dados (primeira execuÃ§Ã£o)

```bash
python coletar_dados_amazonia_azul.py
```

Isso irÃ¡ criar a pasta `data/` com 8 arquivos JSON.

### 5. Execute o chatbot

```bash
streamlit run app.py
```

O app abrirÃ¡ em http://localhost:8501

## ğŸ“¦ Estrutura do Projeto

```
oceania-chatbot/
â”œâ”€â”€ app.py                          # Interface Streamlit
â”œâ”€â”€ rag_engine.py                   # Sistema RAG (embeddings + FAISS)
â”œâ”€â”€ coletar_dados_amazonia_azul.py  # Coleta de dados das APIs
â”œâ”€â”€ requirements.txt                # DependÃªncias Python
â”œâ”€â”€ .env                            # Chaves de API (nÃ£o commitar!)
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ secrets.toml               # Secrets para deploy
â”œâ”€â”€ data/                          # JSONs com dados coletados
â”‚   â”œâ”€â”€ obis_ocorrencias.json
â”‚   â”œâ”€â”€ gbif_ocorrencias.json
â”‚   â”œâ”€â”€ copernicus_oceanografia.json
â”‚   â”œâ”€â”€ icmbio_especies_ameacadas.json
â”‚   â”œâ”€â”€ unidades_conservacao.json
â”‚   â”œâ”€â”€ world_bank_climate.json
â”‚   â”œâ”€â”€ ipcc_relatorios_oceanos.json
â”‚   â””â”€â”€ decada_oceanos.json
â”œâ”€â”€ faiss_index                    # Ãndice vetorial FAISS
â””â”€â”€ chunks_metadata.pkl            # Metadados dos chunks
```

## ğŸŒ Deploy no Streamlit Community Cloud

### 1. Prepare o repositÃ³rio

Certifique-se de que todos os arquivos estÃ£o commitados:

```bash
git add .
git commit -m "Preparando para deploy"
git push origin main
```

**IMPORTANTE**: Adicione `.env` ao `.gitignore`:

```bash
echo ".env" >> .gitignore
```

### 2. Acesse o Streamlit Community Cloud

1. VÃ¡ para https://streamlit.io/cloud
2. FaÃ§a login com GitHub
3. Clique em "New app"

### 3. Configure o deploy

- **Repository**: Selecione `seu-usuario/oceania-chatbot`
- **Branch**: `main`
- **Main file path**: `app.py`

### 4. Configure os Secrets

No painel do Streamlit Cloud, vÃ¡ em **Settings > Secrets** e adicione:

```toml
GROQ_API_KEY = "sua_chave_groq_aqui"
```

### 5. Deploy!

Clique em "Deploy" e aguarde. O Streamlit irÃ¡:
- Instalar as dependÃªncias do `requirements.txt`
- Executar o `app.py`
- Gerar o Ã­ndice FAISS automaticamente

Seu app estarÃ¡ disponÃ­vel em: `https://seu-app.streamlit.app`

## âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### Rebuild do Ã­ndice FAISS

Se vocÃª atualizar os dados JSON, force rebuild:

```python
# No app.py ou rag_engine.py
rag.setup(force_rebuild=True)
```

Ou no Streamlit, use o botÃ£o "ğŸ”„ Recarregar Base de Dados" na sidebar.

### Ajustar nÃºmero de chunks retornados

No `app.py`, funÃ§Ã£o `gerar_resposta`:

```python
resultados = rag.buscar(query, k=5)  # Altere k para mais/menos chunks
```

### Trocar o modelo LLM

No `app.py`, funÃ§Ã£o `gerar_resposta`:

```python
completion = groq_client.chat.completions.create(
    model="llama-3.1-70b-versatile",  # Outros: mixtral-8x7b, llama-3.1-8b
    ...
)
```

### Ajustar temperatura do LLM

```python
temperature=0.1,  # 0.0 = mais factual, 1.0 = mais criativo
```

## ğŸ”’ SeguranÃ§a

- **Nunca commite** sua `GROQ_API_KEY` no cÃ³digo
- Use `.env` localmente e Streamlit Secrets no deploy
- Adicione `.env` ao `.gitignore`

## ğŸ“ LimitaÃ§Ãµes

1. **Conhecimento limitado**: O chatbot responde APENAS com dados da base local
2. **Sem conhecimento geral**: NÃ£o possui informaÃ§Ãµes alÃ©m dos 8 JSONs
3. **Dados estÃ¡ticos**: Dados nÃ£o atualizam automaticamente (requer nova coleta)
4. **Rate limits**: API Groq tem limite de requisiÃ§Ãµes no plano gratuito

## ğŸ› Troubleshooting

### Erro: "GROQ_API_KEY nÃ£o encontrada"

- **Local**: Verifique se `.env` existe e contÃ©m a chave
- **Deploy**: Configure o secret no Streamlit Cloud

### Erro: "Ãndice FAISS nÃ£o encontrado"

Execute localmente primeiro para gerar o Ã­ndice:

```bash
python rag_engine.py
```

### App lento no primeiro acesso

Ã‰ normal! O Streamlit precisa:
1. Carregar modelo de embeddings (~500MB)
2. Carregar Ã­ndice FAISS
3. Inicializar o Groq client

ApÃ³s o cache, fica rÃ¡pido.

## ğŸ“Š EstatÃ­sticas

- **Modelo de embeddings**: 278M parÃ¢metros
- **DimensÃ£o dos vetores**: 768
- **Chunks na base**: ~150-300 (depende dos dados coletados)
- **Tamanho do Ã­ndice FAISS**: ~50-100MB
- **Tempo de resposta**: 2-5 segundos

## ğŸ¤ Contribuindo

Pull requests sÃ£o bem-vindos! Para mudanÃ§as grandes:

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto Ã© de cÃ³digo aberto. Os dados pertencem Ã s suas respectivas fontes oficiais.

## ğŸ™ CrÃ©ditos

Dados fornecidos por:
- OBIS (UNESCO-IOC)
- GBIF
- Copernicus Marine Service
- ICMBio
- Dados.gov.br
- World Bank
- IPCC
- UNESCO Ocean Decade

---

Desenvolvido com ğŸŒŠ para as Ã¡guas brasileiras do Oceano AtlÃ¢ntico
